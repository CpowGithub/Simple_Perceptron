{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please note: This is a coding challenge I set for myself.*\n",
    "\n",
    "## Coding Challenge:\n",
    "1. Get more practice with jupyter notebook\n",
    "2. Get more practice with git\n",
    "3. Get more practice with python\n",
    "3. Write a simple one layer perceptron and show that it is able to learn how to solve AND, OR, NOT Problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a perceptron? \n",
    "\n",
    "The perceptron is a simplified artificial neural network first introduced by Frank Rosenblatt in 1958. In itÂ´s simplest form it consists of a single artificial neuron with adjustable weights and a threshold. \n",
    "\n",
    "![title](Images/Simple_Perceptron.png)\n",
    "\n",
    "*Source: https://i.stack.imgur.com/2MVdW.png*\n",
    "\n",
    "The perceptron is basically nothing more than a linear classifier of the form $x = a_1y_1+a_2y_2+...+a_ny_n$\n",
    "\n",
    "## How does a perceptron \"learn\"?\n",
    "\n",
    "### Calculate the output error\n",
    "\n",
    "$\\delta_j = t_j - o_j$\n",
    "\n",
    "$t_j$(wanted output), \n",
    "\n",
    "$o_j$(network prediction), \n",
    "\n",
    "$\\delta_j$(output error)\n",
    "    \n",
    "\n",
    "### Calculate the change of the weight $w_{ij}$ for the connection between the input cell $i$ and the output cell $j$ \n",
    "\n",
    "$\\Delta w_{ij} = \\alpha * \\delta_j * x_i$ \n",
    "\n",
    "$\\Delta w_{ij}$(the change of the weight $w_{ij}$ for the connection between the input cell $i$ and the output cell $j$)\n",
    "\n",
    "$\\alpha$(learning rate), \n",
    "\n",
    "$x_i$(input neuron $i$)\n",
    "\n",
    "### Update the weights\n",
    "\n",
    "$w_{ij}^{new} = w_{ij}^{old} + \\Delta w_{ij}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Simple_Perceptron(object):\n",
    "    \"\"\"A simple one layer perceptron\n",
    "\n",
    "    :param input_nodes: An int, the number of input nodes\n",
    "    :param output_nodes: An int, the number of output nodes\n",
    "    :param weights: A numpy array of the shape(3,1), the weight matrix\n",
    "    :param activation_function: activation function at the output node -> in this case a step function\n",
    "    :param learning_rate : A float, the learning speed coefficient\n",
    "    :param error : A numpy array, holding the errors for the current epoch\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate = 0.1):\n",
    "        self.input_nodes = 3 # 2 input nodes and 1 bias\n",
    "        self.output_nodes = 1\n",
    "        self.weights = np.random.normal(0, scale=0.1, size=(self.input_nodes, self.output_nodes))\n",
    "        self.activation_function = lambda x : np.heaviside(x, 0)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.error = np.array([[1]])\n",
    "        \n",
    "    def update_weights(self, features, labels, predictions):\n",
    "        \"\"\"Calculate the output error and update the weights\"\"\"\n",
    "        self.error = labels - predictions\n",
    "        delta_weights = self.learning_rate * np.dot(features.T, self.error)\n",
    "        self.weights += delta_weights\n",
    "        \n",
    "    def predict(self, features):\n",
    "        \"\"\" Performance a single feedforward steep through the whole network.\"\"\"\n",
    "        output_layer_input = np.dot(features, self.weights)\n",
    "        output_layer_output = self.activation_function(output_layer_input)\n",
    "        return output_layer_output\n",
    "           \n",
    "    def train(self, features, labels):\n",
    "        \"\"\" Performance a single training steep. Run the feedforward step and update the weights\"\"\"\n",
    "        predictions = self.predict(features)\n",
    "        self.update_weights(features, labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 epochs trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "and_features = np.array([[1,1,1],  # true, true, bias\n",
    "                         [1,0,1],  # true, false, bias\n",
    "                         [0,1,1],  # false, true, bias\n",
    "                         [0,0,1]]) # false, false, bias\n",
    "\n",
    "and_labels = np.array([[1],  # true\n",
    "                       [0],  # false\n",
    "                       [0],  # false\n",
    "                       [0]]) # false\n",
    "\n",
    "and_perceptron = Simple_Perceptron()\n",
    "max_epochs = 100\n",
    "curr_epoch = 0\n",
    "\n",
    "while(sum(and_perceptron.error) != 0 and curr_epoch != max_epochs):\n",
    "    and_perceptron.train(and_features, and_labels)\n",
    "    curr_epoch += 1\n",
    "print(\"{epochs} epochs trained.\".format(epochs=str(curr_epoch)))\n",
    "and_perceptron.predict(and_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epochs trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_features = np.array([[1,1,1],  # true, true, bias\n",
    "                        [1,0,1],  # true, false, bias\n",
    "                        [0,1,1],  # false, true, bias\n",
    "                        [0,0,1]]) # false, false, bias\n",
    "\n",
    "or_labels = np.array([[1],  # true\n",
    "                      [1],  # true\n",
    "                      [1],  # true\n",
    "                      [0]]) # false\n",
    "\n",
    "or_perceptron = Simple_Perceptron()\n",
    "max_epochs = 100\n",
    "curr_epoch = 0\n",
    "\n",
    "while(sum(or_perceptron.error) != 0 and curr_epoch != max_epochs):\n",
    "    or_perceptron.train(or_features, or_labels)\n",
    "    curr_epoch += 1\n",
    "print(\"{epochs} epochs trained.\".format(epochs=str(curr_epoch)))\n",
    "or_perceptron.predict(or_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epochs trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_features = np.array([[1,1,1],  # true, true, bias\n",
    "                         [1,0,1],  # true, false, bias\n",
    "                         [0,1,1],  # false, true, bias\n",
    "                         [0,0,1]]) # false, false, bias\n",
    "\n",
    "not_labels = np.array([[0],  # false\n",
    "                       [0],  # false\n",
    "                       [0],  # false\n",
    "                       [1]]) # true\n",
    "\n",
    "not_perceptron = Simple_Perceptron()\n",
    "max_epochs = 100\n",
    "curr_epoch = 0\n",
    "\n",
    "while(sum(not_perceptron.error) != 0 and curr_epoch != max_epochs):\n",
    "    not_perceptron.train(not_features, not_labels)\n",
    "    curr_epoch += 1\n",
    "print(\"{epochs} epochs trained.\".format(epochs=str(curr_epoch)))\n",
    "not_perceptron.predict(not_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR\n",
    "\n",
    "However, Marvin Minsky and Seymour Papert proved in 1969 that a single-layer perceptron can not resolve the XOR operator (linear separability problem). To solve the XOR problem a multilayer perceptron is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 epochs trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_features = np.array([[1,1,1],  # true, true, bias\n",
    "                         [1,0,1],  # true, false, bias\n",
    "                         [0,1,1],  # false, true, bias\n",
    "                         [0,0,1]]) # false, false, bias\n",
    "\n",
    "xor_labels = np.array([[0],  # false\n",
    "                       [1],  # true\n",
    "                       [1],  # true\n",
    "                       [0]]) # false\n",
    "\n",
    "xor_perceptron = Simple_Perceptron()\n",
    "max_epochs = 100\n",
    "curr_epoch = 0\n",
    "\n",
    "while(sum(xor_perceptron.error) != 0 and curr_epoch != max_epochs):\n",
    "    xor_perceptron.train(xor_features, xor_labels)\n",
    "    curr_epoch += 1\n",
    "print(\"{epochs} epochs trained.\".format(epochs=str(curr_epoch)))\n",
    "xor_perceptron.predict(xor_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
